{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Clone my repository, install wandb and import required libs"
      ],
      "metadata": {
        "id": "ChE9lVEx4dbv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDa935r8Tf9H"
      },
      "outputs": [],
      "source": [
        "!curl -LO https://github.com/Mukesh-V/Acads/archive/refs/heads/master.zip\n",
        "!unzip master.zip\n",
        "!rm master.zip\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ./Acads-master/DL/AS-1"
      ],
      "metadata": {
        "id": "HHLvvKH0VzpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3uWGCvuys-M"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "\n",
        "from keras.datasets import fashion_mnist, mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from activations import *\n",
        "from data_utils import *\n",
        "from nn_utils import *\n",
        "from optimizers import *\n",
        "\n",
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Log the Sample images for the 10 Classes"
      ],
      "metadata": {
        "id": "zugR2zTD4PEw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzvaNnonyNMe"
      },
      "outputs": [],
      "source": [
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "labels = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "for i, label in enumerate(labels):\n",
        "   wandb.init(project=\"FundDL-AS1\")\n",
        "   wandb.run.name = \"Sample-Images-\" + str(i+1)\n",
        "   wandb.log({\"examples\": [wandb.Image(X_train[i*30 + 14], caption=label)]})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training function"
      ],
      "metadata": {
        "id": "YY4egQLk4Wjg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qe3ItdJay2n-"
      },
      "outputs": [],
      "source": [
        "def train():  \n",
        "  wandb.run = None\n",
        "  run = wandb.init(project=\"FundDL-AS1\")\n",
        "  config = wandb.config\n",
        "  wandb.run.name = \"{}_{}_hl{}_bs_{}_ac_{}\".format(experiment, config.loss, \", \".join(map(str, config.nn)), config.batch, config.activation)\n",
        "\n",
        "  beta1 = 0.9\n",
        "  beta2 = 0.999\n",
        "  e = 1e-8\n",
        "  gamma = 0.9\n",
        "\n",
        "  config.nn.insert(0, X_train.shape[0])\n",
        "  config.nn.append(10)\n",
        "  Wb, history, grads = nn_init(config.nn, imode='xavier')\n",
        "  v = history.copy()\n",
        "\n",
        "  for i in range(config.epoch):\n",
        "    loss, val_loss = 0, 0\n",
        "    correct_ones = 0\n",
        "    print(\"Epoch - \", i+1)\n",
        "    for j in range(ntrain):\n",
        "      X = np.reshape(X_train[:, j], (-1, 1))\n",
        "      Y, Hs, As = forward_propagation(X, Wb, config.activation)\n",
        "      if y_train[j] == np.argmax(Y): correct_ones += 1\n",
        "      grads_point = backpropagation(Wb, Y, [y_train[j]], config.activation, config.decay, config.loss, Hs, As)\n",
        "      if config.optimizer == 'sgd':\n",
        "        Wb = gd(Wb, grads_point, config.eta)\n",
        "      else:\n",
        "        for k in range(2):\n",
        "            for l in range(len(Wb[0])):\n",
        "                grads[k][l] += grads_point[k][l]\n",
        "        if not (j+1) % config.batch:\n",
        "          for k in range(2):\n",
        "            for l in range(len(Wb[0])):\n",
        "              grads[k][l] /= config.batch \n",
        "          \n",
        "          if config.optimizer == 'momentum':\n",
        "            Wb, history = momentum(Wb, grads, config.eta, gamma, history)\n",
        "          elif config.optimizer == 'rmsprop':\n",
        "            Wb, history = rmsprop(Wb, grads, config.eta, history, beta1, e)\n",
        "          elif config.optimizer == 'adam':\n",
        "            Wb, history, v = adam(Wb, grads, config.eta, history, v, beta1, beta2, e, i+1)\n",
        "          elif config.optimizer == 'nadam':\n",
        "            Wb, history, v = nadam(Wb, grads, config.eta, history, v, beta1, beta2, e, i+1)\n",
        "        \n",
        "        if config.loss == 'cross_entropy':\n",
        "          loss -= (1/ntrain) * math.log(Y[y_train[j]])\n",
        "        elif config.loss == 'mse':\n",
        "          loss += (1/ntrain) * (np.argmax(Y) - y_train[j])**2\n",
        "\n",
        "    y_hat_val, _, _ = forward_propagation(X_val, Wb, config.activation)\n",
        "    count_val = np.sum(np.argmax(y_hat_val, axis = 0)== y_val)\n",
        "\n",
        "    for j in range(nval):\n",
        "      X_v= np.reshape(X_val[:,j], (-1, 1)) \n",
        "      y_hat_val, _, _ = forward_propagation(X_v, Wb, config.activation)\n",
        "\n",
        "      if config.loss == 'cross_entropy':\n",
        "        val_loss = val_loss - (1/nval)*math.log(y_hat_val[int(y_val[j])])\n",
        "      elif config.loss == 'mse':\n",
        "        val_loss = val_loss + (1/nval)*(np.argmax(y_hat_val) - y_val[j])**2\n",
        "\n",
        "    accuracy = 100*correct_ones/ntrain\n",
        "    val_accuracy = 100*count_val/nval\n",
        "\n",
        "    print(\"Loss:\", loss)\n",
        "    print(\"Accuracy:\",accuracy)\n",
        "    print(\"Validation Loss:\", val_loss)\n",
        "    print(\"Validation Accuracy:\", val_accuracy)\n",
        "\n",
        "    metrics = {'epoch':i, 'val_accuracy': val_accuracy, 'val_loss': val_loss, 'accuracy': accuracy, 'loss': loss}\n",
        "    wandb.log(metrics)\n",
        "\n",
        "  Y_test, _, _ = forward_propagation(X_test, Wb, config.activation)\n",
        "  wandb.log({\"Confusion_Matrix\" : wandb.plot.confusion_matrix(\n",
        "                        probs=None,\n",
        "                        y_true=y_test,\n",
        "                        preds=np.argmax(Y_test, axis = 0),\n",
        "                        class_names=labels)})\n",
        "  run.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fashion-MNIST Cross-entropy and MSE sweeps"
      ],
      "metadata": {
        "id": "TZsKmn8u421b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5iFDjspy8zy"
      },
      "outputs": [],
      "source": [
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "labels = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "X_train = np.reshape(X_train,(X_train.shape[0],X_train.shape[1]*X_train.shape[2]))/255.0\n",
        "X_test = np.reshape(X_test,(X_test.shape[0],X_test.shape[1]*X_test.shape[2]))/255.0\n",
        "X_test = X_test.T\n",
        "     \n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
        "X_train = X_train.T\n",
        "X_val = X_val.T\n",
        "\n",
        "ntrain = X_train.shape[1]\n",
        "nval = X_val.shape[1]\n",
        "\n",
        "experiment = \"fashion-mnist\"\n",
        "\n",
        "ce_sweep_config = {\n",
        "  \"name\": \"Sweep-CE\",\n",
        "  \"method\": \"grid\",\n",
        "  \"project\": \"FundDL-AS1\",\n",
        "  \"metric\":{\n",
        "      \"name\":\"val_accuracy\",\n",
        "      \"goal\":\"maximize\"\n",
        "  },\n",
        "  \"parameters\": {\n",
        "        \"epoch\": {\n",
        "            \"values\": [10, 15, 20]\n",
        "        },\n",
        "        \"nn\": {\n",
        "            \"values\":[[64], [64, 32]]\n",
        "        },\n",
        "        \"decay\":{\n",
        "            \"values\":[0]\n",
        "        },\n",
        "        \"eta\":{\n",
        "            \"values\":[0.001, 0.0005]\n",
        "        },\n",
        "        \"batch\": {\n",
        "            \"values\":[32, 64]\n",
        "        },  \n",
        "        \"optimizer\": {\n",
        "            \"values\":['sgd']\n",
        "        },\n",
        "        \"init\": {\n",
        "            \"values\":['xavier']\n",
        "        },\n",
        "        \"activation\":{\n",
        "            \"values\": ['relu']\n",
        "        },\n",
        "        \"loss\":{\n",
        "            \"values\": ['cross_entropy']\n",
        "        }\n",
        "    }\n",
        "}\n",
        "sweep_id = wandb.sweep(ce_sweep_config)\n",
        "wandb.agent(sweep_id, function=train, count=7)\n",
        "\n",
        "mse_sweep_config = {\n",
        "  \"name\": \"Sweep-MSE\",\n",
        "  \"method\": \"grid\",\n",
        "  \"project\": \"FundDL-AS1\",\n",
        "  \"metric\":{\n",
        "      \"name\":\"val_accuracy\",\n",
        "      \"goal\":\"maximize\"\n",
        "  },\n",
        "  \"parameters\": {\n",
        "        \"epoch\": {\n",
        "            \"values\": [20]\n",
        "        },\n",
        "        \"nn\": {\n",
        "            \"values\":[[64], [256, 128, 64], [64, 32]]\n",
        "        },\n",
        "        \"decay\":{\n",
        "            \"values\":[0, 0.0005]\n",
        "        },\n",
        "        \"eta\":{\n",
        "            \"values\":[0.001, 0.0005]\n",
        "        },\n",
        "        \"batch\": {\n",
        "            \"values\":[32, 64]\n",
        "        },  \n",
        "        \"optimizer\": {\n",
        "            \"values\":['sgd']\n",
        "        },\n",
        "        \"init\": {\n",
        "            \"values\":['xavier']\n",
        "        },\n",
        "        \"activation\":{\n",
        "            \"values\": ['relu']\n",
        "        },\n",
        "        \"loss\":{\n",
        "            \"values\": ['mse']\n",
        "        }\n",
        "    }\n",
        "}\n",
        "sweep_id = wandb.sweep(mse_sweep_config)\n",
        "wandb.agent(sweep_id, function=train, count=7)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MNIST Cross-entropy sweeps"
      ],
      "metadata": {
        "id": "giV3v7mM5BQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = np.reshape(X_train,(X_train.shape[0],X_train.shape[1]*X_train.shape[2]))/255.0\n",
        "X_test = np.reshape(X_test,(X_test.shape[0],X_test.shape[1]*X_test.shape[2]))/255.0\n",
        "X_test = X_test.T\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
        "X_train = X_train.T\n",
        "X_val = X_val.T\n",
        "\n",
        "labels = list(range(10))\n",
        "ntrain = X_train.shape[1]\n",
        "nval = X_val.shape[1]\n",
        "\n",
        "experiment = \"mnist\"\n",
        "\n",
        "mnist_ce_sweep_config = {\n",
        "  \"name\": \"MNIST-Sweep-CE\",\n",
        "  \"method\": \"grid\",\n",
        "  \"project\": \"FundDL-AS1\",\n",
        "  \"metric\":{\n",
        "      \"name\":\"val_accuracy\",\n",
        "      \"goal\":\"maximize\"\n",
        "  },\n",
        "  \"parameters\": {\n",
        "        \"epoch\": {\n",
        "            \"values\": [10]\n",
        "        },\n",
        "        \"nn\": {\n",
        "            \"values\":[[128, 64], [64, 32], [64]]\n",
        "        },\n",
        "        \"decay\":{\n",
        "            \"values\":[0.0005]\n",
        "        },\n",
        "        \"eta\":{\n",
        "            \"values\":[0.0005]\n",
        "        },\n",
        "        \"batch\": {\n",
        "            \"values\":[32, 64]\n",
        "        },  \n",
        "        \"optimizer\": {\n",
        "            \"values\":['sgd', 'momentum']\n",
        "        },\n",
        "        \"init\": {\n",
        "            \"values\":['xavier']\n",
        "        },\n",
        "        \"activation\":{\n",
        "            \"values\": ['relu', 'tanh']\n",
        "        },\n",
        "        \"loss\":{\n",
        "            \"values\": ['cross_entropy']\n",
        "        }\n",
        "    }\n",
        "}\n",
        "sweep_id = wandb.sweep(mnist_ce_sweep_config)\n",
        "wandb.agent(sweep_id, function=train, count=7)"
      ],
      "metadata": {
        "id": "i6F-BsHIp77_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}